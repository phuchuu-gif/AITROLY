# agent_local.py - H·ªó tr·ª£ ch·∫ø ƒë·ªô Chat vs H·ªèi T√†i li·ªáu
import asyncio
from ollama_client import OllamaClient, ChatMessage
from database import db_manager

try:
    from duckduckgo_search import DDGS
    HAS_DDG = True
except ImportError:
    HAS_DDG = False

class LocalConstructionAgent:
    def __init__(self):
        self.llm_client = OllamaClient()
        self.db = db_manager
        
    def _format_history(self, chat_history):
        if not chat_history: return ""
        text = ""
        for msg in chat_history[-4:]: 
            role = "Ng∆∞·ªùi d√πng" if msg['role'] == 'user' else "Tr·ª£ l√Ω"
            content = msg['content'][:500]
            text += f"- {role}: {content}\n"
        return text

    async def process_query(self, user_query: str, workspace_id: str = "main", image_data: str = None, chat_history: list = [], mode: str = "auto"):
        """
        mode: 'auto', 'doc' (H·ªèi t√†i li·ªáu), 'chat' (T√°n g·∫´u)
        """
        plan = []
        
        # 1. X√°c ƒë·ªãnh k·∫ø ho·∫°ch d·ª±a tr√™n MODE
        if image_data: 
            plan.append("analyze_image")
        
        elif mode == "chat":
            # Ch·∫ø ƒë·ªô t√°n g·∫´u: Kh√¥ng t√¨m DB, kh√¥ng t√¨m Web
            print("üó£Ô∏è Mode: T√°n g·∫´u")
            pass 
            
        elif mode == "doc":
            # Ch·∫ø ƒë·ªô t√†i li·ªáu: B·∫Øt bu·ªôc t√¨m DB
            print("üìÑ Mode: H·ªèi t√†i li·ªáu")
            plan.append("search_db")
            
        else: # Auto mode (Logic c≈©)
            q = user_query.lower()
            if any(x in q for x in ['tcvn', 'quy chu·∫©n', 't√†i li·ªáu']): plan.append("search_db")
            elif any(x in q for x in ['gi√°', 'm·ªõi nh·∫•t', 'google']) and HAS_DDG: plan.append("search_web")
            else: plan.append("search_db")

        context_info = ""
        sources = []
        
        # 2. Th·ª±c thi t√¨m ki·∫øm
        if "search_db" in plan:
            print("üìÇ T√¨m DB...")
            results, _ = self.db.rag_search(user_query, workspace_id, top_k=3)
            if results:
                context_info += "\n=== T√ÄI LI·ªÜU N·ªòI B·ªò ===\n"
                for res in results:
                    snip = res.get('content', '')[:200].replace('\n', ' ')
                    context_info += f"- [{res.get('file_name')}]: {snip}...\n"
                    sources.append({"source": res.get('file_name'), "content": snip, "type": "Local DB"})
            else:
                if mode == "doc": 
                    context_info += "\n(Kh√¥ng t√¨m th·∫•y th√¥ng tin n√†o trong t√†i li·ªáu c·ªßa b·∫°n)\n"
        
        if "search_web" in plan and HAS_DDG:
            try:
                with DDGS() as ddgs:
                    web_res = list(ddgs.text(user_query, max_results=2))
                    for w in web_res:
                        context_info += f"- [Web]: {w['body']}\n"
                        sources.append({"source": "Web", "content": w['body'][:100], "type": "Web"})
            except: pass

        # 3. T·ªïng h·ª£p Prompt
        hist = self._format_history(chat_history)
        
        if mode == "chat" and not context_info:
            # Prompt cho ch·∫ø ƒë·ªô t√°n g·∫´u
            prompt = f"""B·∫°n l√† tr·ª£ l√Ω AI th√¢n thi·ªán. H√£y tr√≤ chuy·ªán v·ªõi ng∆∞·ªùi d√πng.
            L·ªãch s·ª≠:
            {hist}
            C√¢u h·ªèi: {user_query}"""
        else:
            # Prompt cho ch·∫ø ƒë·ªô h·ªèi t√†i li·ªáu
            prompt = f"""B·∫°n l√† tr·ª£ l√Ω x√¢y d·ª±ng. D·ª±a v√†o th√¥ng tin sau ƒë·ªÉ tr·∫£ l·ªùi.
            L·ªäCH S·ª¨:
            {hist}
            TH√îNG TIN THAM KH·∫¢O:
            {context_info}
            C√ÇU H·ªéI: {user_query}
            TR·∫¢ L·ªúI (Ti·∫øng Vi·ªát):"""
        
        msg = ChatMessage(role="user", content=prompt, image_data=image_data)
        res = await self.llm_client.chat_completion([msg])
        return res.content, sources

agent_system = LocalConstructionAgent()